{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (1.8.2)\n",
      "Requirement already satisfied: torch in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (0.24.1)\n",
      "Requirement already satisfied: tqdm in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: black>=24.10.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (25.12.0)\n",
      "Requirement already satisfied: bleach in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: kagglesdk in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (0.1.13)\n",
      "Requirement already satisfied: mypy>=1.15.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (1.19.1)\n",
      "Requirement already satisfied: protobuf in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (6.33.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: types-requests in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (2.32.4.20250913)\n",
      "Requirement already satisfied: types-tqdm in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (4.67.0.20250809)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from kaggle) (2.6.2)\n",
      "Requirement already satisfied: filelock in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: numpy in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (8.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (1.1.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (4.5.1)\n",
      "Requirement already satisfied: pytokens>=0.3.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from black>=24.10.0->kaggle) (0.3.0)\n",
      "Requirement already satisfied: librt>=0.6.2 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from mypy>=1.15.0->kaggle) (0.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: webencodings in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from requests->kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from requests->kaggle) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/uvuv/CV/.venv/lib/python3.12/site-packages (from requests->kaggle) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/uvuv/.kaggle/kaggle.json'\n",
      "Downloading dogs-vs-cats.zip to /Users/uvuv/CV/lab3\n",
      "100%|███████████████████████████████████████▉| 810M/812M [00:37<00:00, 22.1MB/s]\n",
      "100%|████████████████████████████████████████| 812M/812M [00:37<00:00, 22.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq dogs-vs-cats.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq train.zip\n",
    "!unzip -qq test1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_NUM = 12500\n",
    "DOG_NUM = 12500\n",
    "\n",
    "train_dir = 'train'\n",
    "test_dir = 'test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uvuv/CV/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from source.model import SimpleNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "TEST_COUNT = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 5\n",
    "IMG_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "def prepare_data(source_dir, target_dir):\n",
    "    if os.path.exists(target_dir):\n",
    "        return\n",
    "\n",
    "    source_path = Path(source_dir)\n",
    "    target_path = Path(target_dir)\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in ['cat', 'dog']:\n",
    "            (target_path / split / cls).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    files = list(source_path.glob('*.jpg'))\n",
    "    cats = [f for f in files if 'cat' in f.name]\n",
    "    dogs = [f for f in files if 'dog' in f.name]\n",
    "    \n",
    "    for category_files, cls in [(cats, 'cat'), (dogs, 'dog')]:\n",
    "        random.shuffle(category_files)\n",
    "        test_files = category_files[:TEST_COUNT]\n",
    "        remaining = category_files[TEST_COUNT:]\n",
    "        split_idx = int(len(remaining) * TRAIN_RATIO)\n",
    "        train_files = remaining[:split_idx]\n",
    "        val_files = remaining[split_idx:]\n",
    "        \n",
    "        for f in test_files: shutil.copy(f, target_path / 'test' / cls / f.name)\n",
    "        for f in train_files: shutil.copy(f, target_path / 'train' / cls / f.name)\n",
    "        for f in val_files: shutil.copy(f, target_path / 'val' / cls / f.name)\n",
    "\n",
    "prepare_data('train', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder('dataset/train', transform=transform_train)\n",
    "val_ds = datasets.ImageFolder('dataset/val', transform=transform_val)\n",
    "test_ds = datasets.ImageFolder('dataset/test', transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mSimpleNet\u001b[49m().to(DEVICE)\n\u001b[32m      4\u001b[39m criterion = nn.CrossEntropyLoss()\n\u001b[32m      5\u001b[39m optimizer = optim.Adam(model.parameters(), lr=LR)\n",
      "\u001b[31mNameError\u001b[39m: name 'SimpleNet' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = SimpleNet().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': running_loss/len(train_loader), 'acc': 100.*correct/total})\n",
    "    \n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    \n",
    "    print(f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {100.*val_correct/val_total:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100.*test_correct/test_total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
